{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNQ/frnB2MlfTVPvP8vGn5/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayman850/COMP257/blob/main/COMP257_Ass3_AymanYasin.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Assignment3 - Question 1"
      ],
      "metadata": {
        "id": "Ls0NF28b58x8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "LjlFnNuZ5-5z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from collections import Counter\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import fetch_olivetti_faces\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, silhouette_score\n",
        "from sklearn.cluster import KMeans, DBSCAN\n",
        "from sklearn.cluster import AgglomerativeClustering\n",
        "from sklearn import metrics\n",
        "from scipy.cluster.hierarchy import dendrogram, linkage, fcluster\n",
        "from scipy.spatial.distance import pdist\n",
        "from scipy.stats import mode"
      ],
      "metadata": {
        "id": "fWBQ3_0C5-bX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Retrieve and load the Olivetti faces dataset"
      ],
      "metadata": {
        "id": "5j1Ni6K-6O7q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "olivetti_faces = fetch_olivetti_faces()\n",
        "X = olivetti_faces.data\n",
        "y = olivetti_faces.target\n",
        "images = olivetti_faces.images # 64x64 version of .data\n",
        "print(X.shape)\n",
        "print(y.shape)"
      ],
      "metadata": {
        "id": "sczar0Vu6QEM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From Reference [1]\n",
        "def show_40_distinct_people(images, unique_ids):\n",
        "    #Creating 4X10 subplots in  18x9 figure size\n",
        "    fig, axarr=plt.subplots(nrows=4, ncols=10, figsize=(18, 9))\n",
        "    #For easy iteration flattened 4X10 subplots matrix to 40 array\n",
        "    axarr=axarr.flatten()\n",
        "\n",
        "    #iterating over user ids\n",
        "    for unique_id in unique_ids:\n",
        "        image_index=unique_id*10\n",
        "        axarr[unique_id].imshow(images[image_index], cmap='gray')\n",
        "        axarr[unique_id].set_xticks([])\n",
        "        axarr[unique_id].set_yticks([])\n",
        "        axarr[unique_id].set_title(\"face id:{}\".format(unique_id))\n",
        "    plt.suptitle(\"There are 40 distinct people in the dataset\")\n",
        "\n",
        "show_40_distinct_people(images, np.unique(y))"
      ],
      "metadata": {
        "id": "9LLaCkE96eIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Split the training set, a validation set, and a test set using stratified sampling to ensure that there are the same number of images per person in each set."
      ],
      "metadata": {
        "id": "Mg2FQDJr6nLj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Split is:\n",
        "80% train\n",
        "10% validation\n",
        "10% test\n",
        "to ensure we have a lot of data to train,\n",
        "and also still have some left for validation and testing\n",
        "'''\n",
        "# First split into train + validation (90%) and test (15%)\n",
        "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "    X, y, test_size=0.1, random_state=42, stratify=y)\n",
        "\n",
        "# Now split the train + validation set (90%) into train (80%) and validation (10%)\n",
        "# 10/90 = 0.1111\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train_val, y_train_val, test_size=0.1111, random_state=42, stratify=y_train_val)"
      ],
      "metadata": {
        "id": "pA_ArnQa6oH7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(X_val.shape)\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "id": "1G6c_bjH6uoX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Using k-fold cross validation, train a classifier to predict which person is represented in each picture, and evaluate it on the validation set."
      ],
      "metadata": {
        "id": "1ZNuOhVT6zod"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use SVC with linear kernel\n",
        "clf = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Instantiate StratifiedKFold\n",
        "# use n_splits=4 so the 8 training samples per class can be evenly distributed\n",
        "kf = StratifiedKFold(n_splits=4, shuffle=True, random_state=42)\n",
        "\n",
        "# Run k-fold CV\n",
        "cv_scores = cross_val_score(clf, X_train, y_train, cv=kf, scoring='accuracy')\n",
        "\n",
        "# Print scores\n",
        "print(f\"Cross-validation accuracy scores: {cv_scores}\")\n",
        "print(f\"Mean cross-validation accuracy: {cv_scores.mean():.4f}\")\n",
        "\n",
        "# Train the classifier on the entire training set\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Evaluate the classifier on the validation set\n",
        "y_val_pred = clf.predict(X_val)\n",
        "val_accuracy = accuracy_score(y_val, y_val_pred)\n",
        "\n",
        "print(f\"Validation set accuracy: {val_accuracy:.4f}\")"
      ],
      "metadata": {
        "id": "O7U-j_Cy6201"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Using either Agglomerative Hierarchical Clustering (AHC) or Divisive Hierarchical Clustering (DHC) and using the centroid-based clustering rule, reduce the dimensionality of the set by using the following similarity measures:"
      ],
      "metadata": {
        "id": "lI5hX-wJ6911"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n_clusters = 40"
      ],
      "metadata": {
        "id": "N4p-ZwdE6--c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# From Reference [2]\n",
        "def fancy_dendrogram(*args, **kwargs):\n",
        "    max_d = kwargs.pop('max_d', None)\n",
        "    if max_d and 'color_threshold' not in kwargs:\n",
        "        kwargs['color_threshold'] = max_d\n",
        "    annotate_above = kwargs.pop('annotate_above', 0)\n",
        "    title = kwargs.pop('title', \"\")\n",
        "    ddata = dendrogram(*args, **kwargs)\n",
        "\n",
        "    if not kwargs.get('no_plot', False):\n",
        "        # plt.title('Hierarchical Clustering Dendrogram (truncated)')\n",
        "        plt.title(title)\n",
        "        plt.xlabel('sample index or (cluster size)')\n",
        "        plt.ylabel('distance')\n",
        "        for i, d, c in zip(ddata['icoord'], ddata['dcoord'], ddata['color_list']):\n",
        "            x = 0.5 * sum(i[1:3])\n",
        "            y = d[1]\n",
        "            if y > annotate_above:\n",
        "                plt.plot(x, y, 'o', c=c)\n",
        "                plt.annotate(\"%.3g\" % y, (x, y), xytext=(0, -5),\n",
        "                             textcoords='offset points',\n",
        "                             va='top', ha='center')\n",
        "        if max_d:\n",
        "            plt.axhline(y=max_d, c='k')\n",
        "    return ddata\n",
        "\n",
        "# Function to simplify code to use fancy_dendrogram()\n",
        "def use_fancy_dendrogram(Z, title, filename):\n",
        "  plt.figure(figsize=(25, 10))\n",
        "  fancy_dendrogram(Z,\n",
        "                 leaf_rotation=90,\n",
        "                 leaf_font_size=12,\n",
        "                 show_contracted=True,\n",
        "                 title=title\n",
        "                )\n",
        "  plt.savefig(filename)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "3ZGZfhEO7CVw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_centroids(X, labels):\n",
        "  unique_labels = np.unique(labels)\n",
        "  centroids_list = []\n",
        "  for i in unique_labels:\n",
        "    # Take points that belong to cluster i\n",
        "    cluster_points = X[labels == i]\n",
        "\n",
        "    # Calculate the mean points of the points in the cluster\n",
        "    centroid = cluster_points.mean(axis=0)\n",
        "\n",
        "    # Add to list\n",
        "    centroids_list.append(centroid)\n",
        "  centroids = np.array(centroids_list)\n",
        "  return centroids"
      ],
      "metadata": {
        "id": "yggn69qy7JpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### a) Euclidean Distance"
      ],
      "metadata": {
        "id": "E5eCon6n7Q1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use euclidean distance\n",
        "dist_euclidean = pdist(X, metric=\"euclidean\")\n",
        "\n",
        "# Perform agglomerative clustering\n",
        "Z_euclidean = linkage(dist_euclidean, method=\"centroid\")\n",
        "\n",
        "# Get labels (which cluster each point belongs to)\n",
        "labels_euclidean = fcluster(Z_euclidean, t=n_clusters, criterion=\"maxclust\")"
      ],
      "metadata": {
        "id": "bkoj4zKn7Ryt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show how data points are merged\n",
        "use_fancy_dendrogram(Z_euclidean, f\"dendrogram_euclidean\", f\"dendrogram_euclidean.png\")"
      ],
      "metadata": {
        "id": "G0VJQxR_7Yjz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reduced dataset\n",
        "X_reduced_euclidean = get_centroids(X, labels_euclidean)\n",
        "X_reduced_euclidean.shape"
      ],
      "metadata": {
        "id": "jaMox2ka7dkd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### b) Minkowski Distance"
      ],
      "metadata": {
        "id": "DOVsVz1L7hao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use minkowski distance (if p=2, equivalent to Euclidean)\n",
        "# p=1 is Manhattan\n",
        "dist_minkowski = pdist(X, metric=\"minkowski\", p=1)\n",
        "\n",
        "# Perform agglomerative clustering\n",
        "Z_minkowski = linkage(dist_minkowski, method=\"centroid\")\n",
        "\n",
        "# Get labels (which cluster each point belongs to)\n",
        "labels_minkowski = fcluster(Z_minkowski, t=n_clusters, criterion=\"maxclust\")"
      ],
      "metadata": {
        "id": "XhDyhoPq7iC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show how data points are merged\n",
        "use_fancy_dendrogram(Z_minkowski, f\"dendrogram_minkowski_p1\", f\"dendrogram_minkowski_p1.png\")"
      ],
      "metadata": {
        "id": "slG0F62C7oOe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reduced dataset\n",
        "X_reduced_minkowski = get_centroids(X, labels_minkowski)\n",
        "X_reduced_minkowski.shape"
      ],
      "metadata": {
        "id": "q0RMYu357tie"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### c) Cosine Similarity"
      ],
      "metadata": {
        "id": "3H2QNk0p7xer"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Methods ‘centroid’, ‘median’, and ‘ward’ are correctly defined only if Euclidean pairwise metric is used. If y is passed as precomputed pairwise distances, then it is the user’s responsibility to assure that these distances are in fact Euclidean, otherwise the produced result will be incorrect.  \n",
        "https://docs.scipy.org/doc/scipy/reference/generated/scipy.cluster.hierarchy.linkage.html"
      ],
      "metadata": {
        "id": "3BiEVH_l73kR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cosine similarity\n",
        "dist_cosine = pdist(X, metric=\"cosine\")\n",
        "\n",
        "# Perform agglomerative clustering\n",
        "Z_cosine = linkage(dist_cosine, method=\"average\")\n",
        "\n",
        "# Get labels (which cluster each point belongs to)\n",
        "labels_cosine = fcluster(Z_cosine, t=n_clusters, criterion=\"maxclust\")"
      ],
      "metadata": {
        "id": "UJa0Tidk7yQ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show how data points are merged\n",
        "use_fancy_dendrogram(Z_cosine, f\"dendrogram_cosine\", f\"dendrogram_cosine.png\")"
      ],
      "metadata": {
        "id": "115qOTyl8Apn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reduced dataset\n",
        "X_reduced_cosine = get_centroids(X, labels_cosine)\n",
        "X_reduced_cosine.shape"
      ],
      "metadata": {
        "id": "_SzbGfUR8HpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5. Discuss any discrepancies observed between 4(a), 4(b), or 4(c). Use the silhouette score approach to choose the number of clusters for 4(a), 4(b), and 4(c)."
      ],
      "metadata": {
        "id": "fg0XmdZO8StX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cluster_range = range(20, 150)\n",
        "silhouette_scores = {\n",
        "    \"euclidean\": [],\n",
        "    \"minkowski\": [],\n",
        "    \"cosine\": []\n",
        "}\n",
        "\n",
        "for c in cluster_range:\n",
        "  print(f\"c: {c}\")\n",
        "  labels_euclidean = fcluster(Z_euclidean, t=c, criterion=\"maxclust\")\n",
        "  labels_minkowski = fcluster(Z_minkowski, t=c, criterion=\"maxclust\")\n",
        "  labels_cosine = fcluster(Z_cosine, t=c, criterion=\"maxclust\")\n",
        "\n",
        "  sil_euclidean = silhouette_score(X, labels_euclidean, metric='euclidean')\n",
        "  sil_minkowski = silhouette_score(X, labels_minkowski, metric='minkowski', p=1)\n",
        "  sil_cosine = silhouette_score(X, labels_cosine, metric='cosine')\n",
        "\n",
        "  silhouette_scores[\"euclidean\"].append(sil_euclidean)\n",
        "  silhouette_scores[\"minkowski\"].append(sil_minkowski)\n",
        "  silhouette_scores[\"cosine\"].append(sil_cosine)\n",
        "\n",
        "optimal_euclidean = cluster_range[np.argmax(silhouette_scores[\"euclidean\"])]\n",
        "optimal_minkowski = cluster_range[np.argmax(silhouette_scores[\"minkowski\"])]\n",
        "optimal_cosine = cluster_range[np.argmax(silhouette_scores[\"cosine\"])]\n",
        "\n",
        "print(f\"Optimal number of clusters for euclidean: {optimal_euclidean}\")\n",
        "print(f\"Optimal number of clusters for minkowski (p=1): {optimal_minkowski}\")\n",
        "print(f\"Optimal number of clusters for cosine: {optimal_cosine}\")"
      ],
      "metadata": {
        "id": "sHxeD2w68TeF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot silhouette scores to visualize the optimal number of clusters\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(cluster_range, silhouette_scores[\"euclidean\"], marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Clusters (Euclidean)')\n",
        "plt.grid(True)\n",
        "plt.savefig(\"silhouette_euclidean.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "PwSi4HUX8dFZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot silhouette scores to visualize the optimal number of clusters\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(cluster_range, silhouette_scores[\"minkowski\"], marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Clusters (Minkowski p=1)')\n",
        "plt.grid(True)\n",
        "plt.savefig(\"silhouette_minkowski_p1.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "X-95GDiz8hCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot silhouette scores to visualize the optimal number of clusters\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(cluster_range, silhouette_scores[\"cosine\"], marker='o')\n",
        "plt.xlabel('Number of Clusters (k)')\n",
        "plt.ylabel('Silhouette Score')\n",
        "plt.title('Silhouette Score vs Number of Clusters (Cosine Similarity)')\n",
        "plt.grid(True)\n",
        "plt.savefig(\"silhouette_cosine.png\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "5VlRdAvP8rNF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6. Use the set from (4(a), 4(b), or 4(c)) to train a classifier as in (3) using k-fold cross validation."
      ],
      "metadata": {
        "id": "yHPWl7Ro80fA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Optimal number of clusters for euclidean: {optimal_euclidean}\")\n",
        "print(f\"Optimal number of clusters for minkowski: {optimal_minkowski}\")\n",
        "print(f\"Optimal number of clusters for cosine: {optimal_cosine}\")"
      ],
      "metadata": {
        "id": "FsIXp1rj83JH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use euclidean distance\n",
        "dist_euclidean = pdist(X, metric=\"euclidean\")\n",
        "\n",
        "# Perform agglomerative clustering\n",
        "Z_euclidean = linkage(dist_euclidean, method=\"centroid\")\n",
        "\n",
        "# Get labels (which cluster each point belongs to)\n",
        "labels_euclidean = fcluster(Z_euclidean, t=optimal_euclidean, criterion=\"maxclust\")"
      ],
      "metadata": {
        "id": "qM7r7sd_8_1C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use minkowski distance (if p=2, equivalent to Euclidean)\n",
        "# p=1 is Manhattan\n",
        "dist_minkowski = pdist(X, metric=\"minkowski\", p=1)\n",
        "\n",
        "# Perform agglomerative clustering\n",
        "Z_minkowski = linkage(dist_minkowski, method=\"centroid\")\n",
        "\n",
        "# Get labels (which cluster each point belongs to)\n",
        "labels_minkowski = fcluster(Z_minkowski, t=optimal_minkowski, criterion=\"maxclust\")"
      ],
      "metadata": {
        "id": "edlZ4RHj9EU1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use cosine similarity\n",
        "dist_cosine = pdist(X, metric=\"cosine\")\n",
        "\n",
        "# Perform agglomerative clustering\n",
        "Z_cosine = linkage(dist_cosine, method=\"average\")\n",
        "\n",
        "# Get labels (which cluster each point belongs to)\n",
        "labels_cosine = fcluster(Z_cosine, t=optimal_cosine, criterion=\"maxclust\")"
      ],
      "metadata": {
        "id": "5fAnRxij9JTc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_y_reduced(y, labels):\n",
        "  y_reduced = []\n",
        "  for i in np.unique(labels):\n",
        "    cluster_indices = np.where(labels == i)\n",
        "\n",
        "    # Get labels of points within this cluster\n",
        "    cluster_labels = y[cluster_indices]\n",
        "\n",
        "    # Get the label with most occurence for this cluster\n",
        "    cluster_label = mode(cluster_labels).mode\n",
        "\n",
        "    y_reduced.append(cluster_label)\n",
        "  return np.array(y_reduced)"
      ],
      "metadata": {
        "id": "1RZcuIi-9NP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get reduced Xs\n",
        "X_reduced_euclidean = get_centroids(X, labels_euclidean)\n",
        "X_reduced_minkowski = get_centroids(X, labels_minkowski)\n",
        "X_reduced_cosine = get_centroids(X, labels_cosine)\n",
        "\n",
        "# Get reduced ys\n",
        "y_reduced_euclidean = get_y_reduced(y, labels_euclidean)\n",
        "y_reduced_minkowski = get_y_reduced(y, labels_minkowski)\n",
        "y_reduced_cosine = get_y_reduced(y, labels_cosine)\n",
        "\n",
        "# Verify shapes\n",
        "print(X_reduced_euclidean.shape)\n",
        "print(y_reduced_euclidean.shape)\n",
        "print(X_reduced_minkowski.shape)\n",
        "print(y_reduced_minkowski.shape)\n",
        "print(X_reduced_cosine.shape)\n",
        "print(y_reduced_cosine.shape)"
      ],
      "metadata": {
        "id": "aQxlCEiw9RT0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# do train val test split like previously\n",
        "# For Euclidean\n",
        "X_train_val_euclidean, X_test_euclidean, y_train_val_euclidean, y_test_euclidean = train_test_split(\n",
        "    X_reduced_euclidean, y_reduced_euclidean, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train_euclidean, X_val_euclidean, y_train_euclidean, y_val_euclidean = train_test_split(\n",
        "    X_train_val_euclidean, y_train_val_euclidean, test_size=0.1111, random_state=42)\n",
        "\n",
        "# For Minkowski\n",
        "X_train_val_minkowski, X_test_minkowski, y_train_val_minkowski, y_test_minkowski = train_test_split(\n",
        "    X_reduced_minkowski, y_reduced_minkowski, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train_minkowski, X_val_minkowski, y_train_minkowski, y_val_minkowski = train_test_split(\n",
        "    X_train_val_minkowski, y_train_val_minkowski, test_size=0.1111, random_state=42)\n",
        "\n",
        "# For Cosine Similarity\n",
        "X_train_val_cosine, X_test_cosine, y_train_val_cosine, y_test_cosine = train_test_split(\n",
        "    X_reduced_cosine, y_reduced_cosine, test_size=0.1, random_state=42)\n",
        "\n",
        "X_train_cosine, X_val_cosine, y_train_cosine, y_val_cosine = train_test_split(\n",
        "    X_train_val_cosine, y_train_val_cosine, test_size=0.1111, random_state=42)"
      ],
      "metadata": {
        "id": "4Vv-LIuA9WW9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Euclidean Shapes:\")\n",
        "print(\"X_train_euclidean:\", X_train_euclidean.shape)\n",
        "print(\"y_train_euclidean:\", y_train_euclidean.shape)\n",
        "print(\"X_val_euclidean:\", X_val_euclidean.shape)\n",
        "print(\"y_val_euclidean:\", y_val_euclidean.shape)\n",
        "print(\"X_test_euclidean:\", X_test_euclidean.shape)\n",
        "print(\"y_test_euclidean:\", y_test_euclidean.shape)\n",
        "print()\n",
        "print(\"Minkowski (p=1) Shapes:\")\n",
        "print(\"X_train_minkowski:\", X_train_minkowski.shape)\n",
        "print(\"y_train_minkowski:\", y_train_minkowski.shape)\n",
        "print(\"X_val_minkowski:\", X_val_minkowski.shape)\n",
        "print(\"y_val_minkowski:\", y_val_minkowski.shape)\n",
        "print(\"X_test_minkowski:\", X_test_minkowski.shape)\n",
        "print(\"y_test_minkowski:\", y_test_minkowski.shape)\n",
        "print()\n",
        "print(\"Cosine Shapes:\")\n",
        "print(\"X_train_cosine:\", X_train_cosine.shape)\n",
        "print(\"y_train_cosine:\", y_train_cosine.shape)\n",
        "print(\"X_val_cosine:\", X_val_cosine.shape)\n",
        "print(\"y_val_cosine:\", y_val_cosine.shape)\n",
        "print(\"X_test_cosine:\", X_test_cosine.shape)\n",
        "print(\"y_test_cosine:\", y_test_cosine.shape)"
      ],
      "metadata": {
        "id": "VM7bR5iQ9X2e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use SVC with linear kernel\n",
        "clf = SVC(kernel='linear', random_state=42)\n",
        "\n",
        "# Instantiate StratifiedKFold\n",
        "kf = StratifiedKFold(n_splits=2, shuffle=True, random_state=42)\n",
        "\n",
        "# Use SVC with linear kernel for Euclidean reduced dataset\n",
        "cv_scores_euclidean = cross_val_score(clf, X_train_euclidean, y_train_euclidean, cv=kf, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy (Euclidean): {cv_scores_euclidean}\")\n",
        "print(f\"Mean Accuracy (Euclidean): {cv_scores_euclidean.mean():.4f}\")\n",
        "\n",
        "# Use SVC with linear kernel for Minkowski reduced dataset\n",
        "cv_scores_minkowski = cross_val_score(clf, X_train_minkowski, y_train_minkowski, cv=kf, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy (Minkowski p=1): {cv_scores_minkowski}\")\n",
        "print(f\"Mean Accuracy (Minkowski p=1): {cv_scores_minkowski.mean():.4f}\")\n",
        "\n",
        "# Use SVC with linear kernel for Cosine reduced dataset\n",
        "cv_scores_cosine = cross_val_score(clf, X_train_cosine, y_train_cosine, cv=kf, scoring='accuracy')\n",
        "print(f\"Cross-Validation Accuracy (Cosine): {cv_scores_cosine}\")\n",
        "print(f\"Mean Accuracy (Cosine): {cv_scores_cosine.mean():.4f}\")"
      ],
      "metadata": {
        "id": "vEhzuLs49fhe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the classifier on the entire Euclidean training set\n",
        "clf.fit(X_train_euclidean, y_train_euclidean)\n",
        "\n",
        "# Evaluate the classifier on the Euclidean validation set\n",
        "y_val_pred_euclidean = clf.predict(X_val_euclidean)\n",
        "val_accuracy_euclidean = accuracy_score(y_val_euclidean, y_val_pred_euclidean)\n",
        "\n",
        "print(f\"Validation set accuracy (Euclidean): {val_accuracy_euclidean:.4f}\")\n",
        "\n",
        "# Train the classifier on the entire Minkowski training set\n",
        "clf.fit(X_train_minkowski, y_train_minkowski)\n",
        "\n",
        "# Evaluate the classifier on the Minkowski validation set\n",
        "y_val_pred_minkowski = clf.predict(X_val_minkowski)\n",
        "val_accuracy_minkowski = accuracy_score(y_val_minkowski, y_val_pred_minkowski)\n",
        "\n",
        "print(f\"Validation set accuracy (Minkowski p=1): {val_accuracy_minkowski:.4f}\")\n",
        "\n",
        "# Train the classifier on the entire Cosine training set\n",
        "clf.fit(X_train_cosine, y_train_cosine)\n",
        "\n",
        "# Evaluate the classifier on the Cosine validation set\n",
        "y_val_pred_cosine = clf.predict(X_val_cosine)\n",
        "val_accuracy_cosine = accuracy_score(y_val_cosine, y_val_pred_cosine)\n",
        "\n",
        "print(f\"Validation set accuracy (Cosine): {val_accuracy_cosine:.4f}\")"
      ],
      "metadata": {
        "id": "CtqEqKCM9kaU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References  \n",
        "[1] https://www.kaggle.com/code/serkanpeldek/face-recognition-on-olivetti-dataset  \n",
        "[2] https://joernhees.de/blog/2015/08/26/scipy-hierarchical-clustering-and-dendrogram-tutorial/"
      ],
      "metadata": {
        "id": "mBMD2Zuz9mQb"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A3OuGnj99rFI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}